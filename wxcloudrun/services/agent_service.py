"""
Agent æœåŠ¡ - æ ¸å¿ƒå¯¹è¯å¤„ç†é€»è¾‘
"""
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Generator, Optional
import threading

from wxcloudrun.model import Baby
from wxcloudrun.services.context_collector import ContextCollector
from wxcloudrun.services.llm_service import LLMService
from wxcloudrun.services.tool_executor import ToolExecutor, TOOLS

logger = logging.getLogger('log')


class ConversationStore:
    """
    å¯¹è¯å­˜å‚¨ (å†…å­˜ç‰ˆæœ¬)

    ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ Redis æ›¿ä»£
    """

    def __init__(self, max_conversations: int = 1000, ttl_seconds: int = 3600):
        self._store: Dict[str, Dict] = {}
        self._lock = threading.Lock()
        self.max_conversations = max_conversations
        self.ttl_seconds = ttl_seconds

    def get(self, conversation_id: str) -> Optional[Dict]:
        """è·å–å¯¹è¯"""
        with self._lock:
            conv = self._store.get(conversation_id)
            if conv and self._is_expired(conv):
                del self._store[conversation_id]
                return None
            return conv

    def set(self, conversation_id: str, data: Dict):
        """è®¾ç½®å¯¹è¯"""
        with self._lock:
            self._cleanup_if_needed()
            data['last_active'] = datetime.now()
            self._store[conversation_id] = data

    def update_messages(self, conversation_id: str, messages: List[Dict]):
        """æ›´æ–°å¯¹è¯æ¶ˆæ¯"""
        with self._lock:
            if conversation_id in self._store:
                self._store[conversation_id]['messages'] = messages
                self._store[conversation_id]['last_active'] = datetime.now()

    def _is_expired(self, conv: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        last_active = conv.get('last_active', datetime.min)
        return (datetime.now() - last_active).total_seconds() > self.ttl_seconds

    def _cleanup_if_needed(self):
        """æ¸…ç†è¿‡æœŸå¯¹è¯"""
        if len(self._store) >= self.max_conversations:
            expired = [k for k, v in self._store.items() if self._is_expired(v)]
            for k in expired:
                del self._store[k]


# å…¨å±€å¯¹è¯å­˜å‚¨
conversation_store = ConversationStore()


class AgentService:
    """AgentæœåŠ¡ - å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ"""

    SYSTEM_PROMPT = """ä½ æ˜¯å‘¦å‘¦è¾…é£Ÿçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©å®¶é•¿è®°å½•å’Œç®¡ç†å®å®çš„è¾…é£Ÿæƒ…å†µã€‚

ä½ çš„ä¸»è¦èŒè´£ï¼š
1. è®°å½•å®å®çš„ç‰¹æ®ŠçŠ¶æ€ï¼ˆç”Ÿç—…ã€æ‰“ç–«è‹—ç­‰ï¼‰- ä½¿ç”¨ create_special_status å·¥å…·
2. è®°å½•å®å®çš„è¿›é£Ÿæƒ…å†µ - ä½¿ç”¨ create_meal_record å·¥å…·
3. è®°å½•å®å®çš„è¿‡æ•ååº” - ä½¿ç”¨ report_allergy å·¥å…·
4. å›ç­”å…³äºå®å®å–‚å…»ã€å¥åº·ã€æ—©æ•™ç­‰é—®é¢˜ - ä½¿ç”¨ answer_question å·¥å…·

é‡è¦è§„åˆ™ï¼š
1. å½“ç”¨æˆ·æè¿°çš„ä¿¡æ¯ä¸å®Œæ•´æ—¶ï¼ˆå¦‚ç¼ºå°‘æ—¥æœŸã€é¤æ¬¡ç­‰ï¼‰ï¼Œä½¿ç”¨ ask_clarification å·¥å…·å‹å¥½åœ°è¯¢é—®
2. å¦‚æœç”¨æˆ·è¯´"ä»Šå¤©"ã€"æ˜¨å¤©"ç­‰ç›¸å¯¹æ—¥æœŸï¼Œæ ¹æ®å½“å‰æ—¥æœŸè½¬æ¢ä¸ºå…·ä½“æ—¥æœŸ
3. å¯¹äºéœ€è¦æ—¥æœŸä½†ç”¨æˆ·æœªæä¾›çš„æƒ…å†µï¼Œè¦è¯¢é—®ç¡®è®¤ï¼ˆä¾‹å¦‚ï¼š"æ˜¯ä»Šå¤©ç”Ÿç—…çš„å—ï¼Ÿ"ï¼‰
4. å§‹ç»ˆä¿æŒå‹å¥½ã€äº²åˆ‡ã€ä¸“ä¸šçš„è¯­æ°”
5. æ³¨æ„å®å®çš„æœˆé¾„ï¼Œç»™å‡ºé€‚åˆæœˆé¾„çš„å»ºè®®
6. è®°å½•æˆåŠŸåï¼Œç»™äºˆæ­£é¢çš„åé¦ˆå’Œå¿…è¦çš„æé†’

ä»¥ä¸‹æ˜¯å½“å‰å®å®çš„ç›¸å…³ä¿¡æ¯ï¼š

{context}
"""

    def __init__(self, baby: Baby, user_id: int):
        self.baby = baby
        self.user_id = user_id
        self.context_collector = ContextCollector(baby, user_id)
        self.llm_service = LLMService()
        self.tool_executor = ToolExecutor(baby, user_id)

    def chat_stream(
        self,
        message: str,
        conversation_id: str
    ) -> Generator[Dict[str, Any], None, None]:
        """
        æµå¼å¯¹è¯å¤„ç†

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_id: å¯¹è¯ID

        Yields:
            æµå¼å“åº”å—:
            - {'type': 'text', 'content': '...'} - æ–‡æœ¬å†…å®¹
            - {'type': 'tool_calling', 'tool': '...'} - æ­£åœ¨è°ƒç”¨å·¥å…·
            - {'type': 'tool_result', 'tool': '...', 'success': bool, 'result': {...}} - å·¥å…·ç»“æœ
            - {'type': 'error', 'content': '...'} - é”™è¯¯
            - {'type': 'done'} - ç»“æŸ
        """
        # è·å–æˆ–åˆ›å»ºå¯¹è¯
        conversation = conversation_store.get(conversation_id)
        if not conversation:
            conversation = {
                'id': conversation_id,
                'baby_id': self.baby.id,
                'messages': [],
                'created_at': datetime.now()
            }
            conversation_store.set(conversation_id, conversation)

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        context_prompt = self.context_collector.to_prompt()
        system_message = {
            'role': 'system',
            'content': self.SYSTEM_PROMPT.format(context=context_prompt)
        }

        # å†å²æ¶ˆæ¯ + å½“å‰æ¶ˆæ¯
        messages = [system_message] + conversation['messages'] + [
            {'role': 'user', 'content': message}
        ]

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        conversation['messages'].append({'role': 'user', 'content': message})

        # è°ƒç”¨LLM
        full_content = ''

        for chunk in self.llm_service.chat_stream(messages, tools=TOOLS, model_type='fast'):
            if chunk['type'] == 'text':
                full_content += chunk['content']
                yield {'type': 'text', 'content': chunk['content']}

            elif chunk['type'] == 'tool_call':
                tool = chunk['tool']
                tool_name = tool.get('name', '')
                yield {'type': 'tool_calling', 'tool': tool_name}

                # è§£æå‚æ•°
                try:
                    arguments = json.loads(tool.get('arguments', '{}'))
                except json.JSONDecodeError:
                    arguments = {}

                # æ‰§è¡Œå·¥å…·
                success, result = self.tool_executor.execute(tool_name, arguments)

                yield {
                    'type': 'tool_result',
                    'tool': tool_name,
                    'success': success,
                    'result': result
                }

                # æ ¹æ®å·¥å…·ç»“æœå†³å®šä¸‹ä¸€æ­¥
                if result.get('type') == 'clarification':
                    # éœ€è¦è¿½é—®
                    question = result.get('question', '')
                    yield {'type': 'text', 'content': question}
                    full_content = question

                elif result.get('type') == 'answer':
                    # éœ€è¦ä½¿ç”¨é«˜çº§æ¨¡å‹å›ç­”
                    yield from self._answer_with_advanced_model(
                        message, conversation, context_prompt
                    )
                    return

                elif success:
                    # å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œç”Ÿæˆç¡®è®¤æ¶ˆæ¯
                    confirm_msg = result.get('message', 'æ“ä½œå®Œæˆ')
                    note = result.get('note', '')
                    if note:
                        confirm_msg += f"\n\nğŸ’¡ {note}"
                    yield {'type': 'text', 'content': confirm_msg}
                    full_content = confirm_msg

                else:
                    # å·¥å…·æ‰§è¡Œå¤±è´¥
                    error_msg = result.get('error', 'æ“ä½œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•')
                    yield {'type': 'text', 'content': f"æŠ±æ­‰ï¼Œ{error_msg}"}
                    full_content = f"æŠ±æ­‰ï¼Œ{error_msg}"

            elif chunk['type'] == 'error':
                yield {'type': 'error', 'content': chunk.get('content', 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨')}
                return

            elif chunk['type'] == 'done':
                break

        # æ›´æ–°å¯¹è¯å†å²
        if full_content:
            conversation['messages'].append({
                'role': 'assistant',
                'content': full_content
            })
            conversation_store.update_messages(conversation_id, conversation['messages'])

        yield {'type': 'done'}

    def _answer_with_advanced_model(
        self,
        question: str,
        conversation: Dict,
        context_prompt: str
    ) -> Generator[Dict[str, Any], None, None]:
        """ä½¿ç”¨é«˜çº§æ¨¡å‹å›ç­”å¤æ‚é—®é¢˜"""
        system_message = {
            'role': 'system',
            'content': f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€å‹å¥½çš„è‚²å„¿é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹å®å®ä¿¡æ¯ï¼Œå›ç­”å®¶é•¿çš„é—®é¢˜ã€‚

å›ç­”è¦æ±‚ï¼š
1. ä¸“ä¸šã€å‡†ç¡®ã€æ˜“æ‡‚
2. è€ƒè™‘å®å®çš„æœˆé¾„ç»™å‡ºé€‚åˆçš„å»ºè®®
3. å¦‚æœæ¶‰åŠåŒ»å­¦é—®é¢˜ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
4. è¯­æ°”äº²åˆ‡å‹å¥½

{context_prompt}
"""
        }

        messages = [system_message, {'role': 'user', 'content': question}]

        full_content = ''
        for chunk in self.llm_service.chat_stream(messages, model_type='advanced'):
            if chunk['type'] == 'text':
                full_content += chunk['content']
                yield {'type': 'text', 'content': chunk['content']}
            elif chunk['type'] in ('finish', 'done'):
                break
            elif chunk['type'] == 'error':
                yield {'type': 'error', 'content': chunk.get('content', 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨')}
                return

        # æ›´æ–°å¯¹è¯å†å²
        if full_content:
            conversation['messages'].append({
                'role': 'assistant',
                'content': full_content
            })
            conversation_store.update_messages(conversation['id'], conversation['messages'])

        yield {'type': 'done'}

    def get_conversation_messages(self, conversation_id: str) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²æ¶ˆæ¯"""
        conversation = conversation_store.get(conversation_id)
        if not conversation:
            return []
        return conversation.get('messages', [])
